{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ete3\n",
    "ncbi = ete3.NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "species='Yersinia pestis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB = pd.read_table(\"/Users/thesis/Desktop/Google Drive/thesis-lorenz/Work in progress.../Databases/Extracted datasets/\"+str(species), usecols=lambda x:x !=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 'http://www.uniprot.org'\n",
    "KB_ENDPOINT = '/uniprot/'\n",
    "TOOL_ENDPOINT = '/uploadlists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid=ncbi.get_name_translator([species])[species][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proteome_query(taxon):\n",
    "    payload = {'query': 'taxonomy:'+str(taxon),\n",
    "           'format': 'list'}\n",
    "\n",
    "    result2 = requests.get(BASE + KB_ENDPOINT, params=payload)\n",
    "    \n",
    "\n",
    "    if result2.ok:\n",
    "        output = set(result2.text.split())\n",
    "        return output\n",
    "    else:\n",
    "        print('Something went wrong ', result.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_list = proteome_query(taxid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000000 lines\n",
      "Processed 20000000 lines\n",
      "Processed 30000000 lines\n",
      "Processed 40000000 lines\n",
      "Processed 50000000 lines\n",
      "Processed 60000000 lines\n",
      "Processed 70000000 lines\n",
      "Processed 80000000 lines\n",
      "Processed 90000000 lines\n",
      "Processed 100000000 lines\n",
      "Processed 110000000 lines\n",
      "Processed 120000000 lines\n",
      "Processed 130000000 lines\n",
      "Processed 140000000 lines\n",
      "Processed 150000000 lines\n",
      "Processed 160000000 lines\n",
      "Processed 170000000 lines\n",
      "Processed 180000000 lines\n",
      "Processed 190000000 lines\n",
      "Processed 200000000 lines\n",
      "Processed 210000000 lines\n",
      "Processed 220000000 lines\n",
      "Processed 230000000 lines\n",
      "Processed 240000000 lines\n",
      "Processed 250000000 lines\n",
      "Processed 260000000 lines\n",
      "Processed 270000000 lines\n",
      "Processed 280000000 lines\n",
      "Processed 290000000 lines\n",
      "Processed 300000000 lines\n",
      "Processed 310000000 lines\n",
      "Processed 320000000 lines\n",
      "Processed 330000000 lines\n",
      "Processed 340000000 lines\n",
      "Processed 350000000 lines\n",
      "Processed 360000000 lines\n",
      "Processed 370000000 lines\n",
      "Processed 380000000 lines\n",
      "Processed 390000000 lines\n",
      "Processed 400000000 lines\n",
      "Processed 410000000 lines\n",
      "Processed 420000000 lines\n",
      "Processed 430000000 lines\n",
      "Processed 440000000 lines\n",
      "Processed 450000000 lines\n",
      "Processed 460000000 lines\n",
      "Processed 470000000 lines\n",
      "Processed 480000000 lines\n"
     ]
    }
   ],
   "source": [
    "#zelfde code als hierboven maar dan voor de grote file\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/protein2ipr.dat','r') as f:\n",
    "    with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_' + species+ '_out.txt','w') as w:\n",
    "        outer_counter = 0\n",
    "        for line in f:\n",
    "            outer_counter += 1\n",
    "            if outer_counter % 10000000 == 0:\n",
    "                print('Processed',outer_counter,'lines')\n",
    "            l = line.split('\\t')\n",
    "            if l[0] in prot_list:\n",
    "                w.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#de code in de cellen vanaf de deze was die om de dictionaries te maken\n",
    "#Ik laat die nog staan omdat die mss nog handig kunnen zijn\n",
    "IPR_entry=[]\n",
    "P2IPR_full={}\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_' + str(species)+ '_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_full[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[] \n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append((l[1],l[2]))\n",
    "        \n",
    "for key in P2IPR_full.keys():\n",
    "    P2IPR_full[key]=list(pd.unique(P2IPR_full[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_ID={}\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_' + str(species)+ '_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_ID[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[1])\n",
    "for key in P2IPR_ID.keys():\n",
    "    P2IPR_ID[key]=list(pd.unique(P2IPR_ID[key]))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_name={}\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_' + str(species)+ '_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_name[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[2])\n",
    "        \n",
    "for key in P2IPR_name.keys():\n",
    "    P2IPR_name[key]=list(pd.unique(P2IPR_name[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_terms(ID):\n",
    "    if ID in P2IPR_ID.keys():\n",
    "        return P2IPR_ID[ID]\n",
    "    else:\n",
    "        return None\n",
    "def Find_proteins(IPR):\n",
    "    outp = []\n",
    "    for key in P2IPR_ID:\n",
    "        if IPR in P2IPR_ID[key]:\n",
    "            outp.append(key)\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB['IPR_A']=Int_DB.Protein_A.apply(lambda x: Find_terms(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_full_hum={}\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_human_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_full_hum[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[] \n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append((l[1],l[2]))\n",
    "        \n",
    "for key in P2IPR_full_hum.keys():\n",
    "    P2IPR_full_hum[key]=list(pd.unique(P2IPR_full_hum[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_ID_hum={}\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_human_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_ID_hum[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[1])\n",
    "for key in P2IPR_ID_hum.keys():\n",
    "    P2IPR_ID_hum[key]=list(pd.unique(P2IPR_ID_hum[key]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_name_hum={}\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_human_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_name_hum[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[2])\n",
    "        \n",
    "for key in P2IPR_name_hum.keys():\n",
    "    P2IPR_name_hum[key]=list(pd.unique(P2IPR_name_hum[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_terms_hum(ID):\n",
    "    if ID in P2IPR_ID_hum.keys():\n",
    "        return P2IPR_ID_hum[ID]\n",
    "    else:\n",
    "        return None\n",
    "def Find_proteins_hum(IPR):\n",
    "    outp = []\n",
    "    for key in P2IPR_ID_hum:\n",
    "        if IPR in P2IPR_ID_hum[key]:\n",
    "            outp.append(key)\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB['IPR_B']=Int_DB.Protein_B.apply(lambda x: Find_terms_hum(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB.to_csv(\"/Volumes/Biomina_D2/thesis-lorenz/Int_DB_IPR_\" + species, sep =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

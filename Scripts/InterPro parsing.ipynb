{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import ete3\n",
    "ncbi = ete3.NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "species='Francisella tularensis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB = pd.read_table(\"/Users/thesis/Desktop/Google Drive/thesis-lorenz/Work in progress.../Databases/Extracted datasets/\"+str(species), usecols=lambda x:x !=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 'http://www.uniprot.org'\n",
    "KB_ENDPOINT = '/uniprot/'\n",
    "TOOL_ENDPOINT = '/uploadlists/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid=ncbi.get_name_translator([species])[species][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def proteome_query(taxon):\n",
    "    payload = {'query': 'taxonomy:'+str(taxon),\n",
    "           'format': 'list'}\n",
    "\n",
    "    result2 = requests.get(BASE + KB_ENDPOINT, params=payload)\n",
    "    \n",
    "\n",
    "    if result2.ok:\n",
    "        output = set(result2.text.split())\n",
    "        return output\n",
    "    else:\n",
    "        print('Something went wrong ', result.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prot_list = proteome_query(taxid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#zelfde code als hierboven maar dan voor de grote file\n",
    "with open ('/Volumes/Biomina_D2/thesis-lorenz/protein2ipr.dat','r') as f:\n",
    "    with open ('/Volumes/Biomina_D2/thesis-lorenz/ipr_' + species+ '_out.txt','w') as w:\n",
    "        outer_counter = 0\n",
    "        for line in f:\n",
    "            outer_counter += 1\n",
    "            if outer_counter % 10000000 == 0:\n",
    "                print('Processed',outer_counter,'lines')\n",
    "            l = line.split('\\t')\n",
    "            if l[0] in prot_list:\n",
    "                w.write(line)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#de code in de cellen vanaf de deze was die om de dictionaries te maken\n",
    "#Ik laat die nog staan omdat die mss nog handig kunnen zijn\n",
    "IPR_entry=[]\n",
    "P2IPR_full={}\n",
    "with open ('/Users/thesis/Desktop/ipr_' + str(species)+ '_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_full[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[] \n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append((l[1],l[2]))\n",
    "        \n",
    "for key in P2IPR_full.keys():\n",
    "    P2IPR_full[key]=list(pd.unique(P2IPR_full[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_ID={}\n",
    "with open ('/Users/thesis/Desktop/ipr_' + str(species)+ '_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_ID[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[1])\n",
    "for key in P2IPR_ID.keys():\n",
    "    P2IPR_ID[key]=list(pd.unique(P2IPR_ID[key]))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_name={}\n",
    "with open ('/Users/thesis/Desktop/ipr_' + str(species)+ '_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_name[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[2])\n",
    "        \n",
    "for key in P2IPR_name.keys():\n",
    "    P2IPR_name[key]=list(pd.unique(P2IPR_name[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_terms(ID):\n",
    "    if ID in P2IPR_ID.keys():\n",
    "        return P2IPR_ID[ID]\n",
    "    else:\n",
    "        return None\n",
    "def Find_proteins(IPR):\n",
    "    outp = []\n",
    "    for key in P2IPR_ID:\n",
    "        if IPR in P2IPR_ID[key]:\n",
    "            outp.append(key)\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB['IPR_A']=Int_DB.Protein_A.apply(lambda x: Find_terms(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_full_hum={}\n",
    "with open ('/Users/thesis/Desktop/ipr_human_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_full_hum[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[] \n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append((l[1],l[2]))\n",
    "        \n",
    "for key in P2IPR_full_hum.keys():\n",
    "    P2IPR_full_hum[key]=list(pd.unique(P2IPR_full_hum[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_ID_hum={}\n",
    "with open ('/Users/thesis/Desktop/ipr_human_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_ID_hum[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[1])\n",
    "for key in P2IPR_ID_hum.keys():\n",
    "    P2IPR_ID_hum[key]=list(pd.unique(P2IPR_ID_hum[key]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPR_entry=[]\n",
    "P2IPR_name_hum={}\n",
    "with open ('/Users/thesis/Desktop/ipr_human_out.txt','r') as f:\n",
    "    for line in f:\n",
    "        l = line.split('\\t')\n",
    "        if l[0] not in IPR_entry:\n",
    "            if IPR_entry != []:\n",
    "                P2IPR_name_hum[IPR_entry[0]]=IPR_entry[1:]\n",
    "                IPR_entry =[]\n",
    "            IPR_entry.append(l[0])\n",
    "        IPR_entry.append(l[2])\n",
    "        \n",
    "for key in P2IPR_name_hum.keys():\n",
    "    P2IPR_name_hum[key]=list(pd.unique(P2IPR_name_hum[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_terms_hum(ID):\n",
    "    if ID in P2IPR_ID_hum.keys():\n",
    "        return P2IPR_ID_hum[ID]\n",
    "    else:\n",
    "        return None\n",
    "def Find_proteins_hum(IPR):\n",
    "    outp = []\n",
    "    for key in P2IPR_ID_hum:\n",
    "        if IPR in P2IPR_ID_hum[key]:\n",
    "            outp.append(key)\n",
    "    return outp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB['IPR_B']=Int_DB.Protein_B.apply(lambda x: Find_terms_hum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB.to_csv(\"/Users/thesis/Desktop/Int_DB_IPR_\" + species, sep =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB = pd.read_table('/Users/thesis/Desktop/Int_DB_IPR_GO2_'+ species,usecols=lambda x:x !=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1 = Int_DB.IPR_A.isnull()\n",
    "sel2 = Int_DB.IPR_B.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB.loc[sel1,'IPR_A'] = Int_DB.loc[sel1,'Protein_A'].apply(lambda x: Find_terms(x))\n",
    "Int_DB.loc[sel2,'IPR_B'] = Int_DB.loc[sel2,'Protein_B'].apply(lambda x: Find_terms_hum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int_DB.to_csv(\"/Users/thesis/Desktop/Int_DB_IPR2_GO2_\" + species, sep =\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
